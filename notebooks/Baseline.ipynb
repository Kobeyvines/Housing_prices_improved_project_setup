{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Baseline Model\n",
    "\n",
    "This notebook establishes a baseline model and tests the end-to-end ML pipeline including preprocessing, feature engineering, and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    StackingRegressor,\n",
    "    VotingRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1439, 81)\n",
      "Test set shape: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/HOUSE PRICES - ADVANCED REGRESSION TECHNIQUES/data/02-preprocessed/train_preprocessed.csv\"\n",
    ")\n",
    "test_df = pd.read_csv(\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/HOUSE PRICES - ADVANCED REGRESSION TECHNIQUES/data/02-preprocessed/test_preprocessed.csv\"\n",
    ")\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set after outlier removal: (1439, 81)\n"
     ]
    }
   ],
   "source": [
    "outlier_indices = [\n",
    "    598,\n",
    "    955,\n",
    "    935,\n",
    "    1299,\n",
    "    250,\n",
    "    314,\n",
    "    336,\n",
    "    707,\n",
    "    379,\n",
    "    1183,\n",
    "    692,\n",
    "    186,\n",
    "    441,\n",
    "    524,\n",
    "    739,\n",
    "    636,\n",
    "    1062,\n",
    "    1191,\n",
    "    496,\n",
    "    198,\n",
    "    1338,\n",
    "]\n",
    "train_df = train_df[train_df.Id.isin(outlier_indices) == False]\n",
    "print(f\"Train set after outlier removal: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8684/2948010274.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna('No', inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna('No', inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['BsmtFinType1'].fillna('Unf', inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['BsmtFinType1'].fillna('Unf', inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Electrical'].fillna('SBrkr', inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Electrical'].fillna('SBrkr', inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['LotFrontage'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['LotFrontage'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['MasVnrArea'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_8684/2948010274.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['MasVnrArea'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "categorical_fillna = [\n",
    "    \"Alley\",\n",
    "    \"Fence\",\n",
    "    \"MasVnrType\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageCond\",\n",
    "    \"GarageType\",\n",
    "    \"GarageFinish\",\n",
    "    \"GarageQual\",\n",
    "    \"BsmtExposure\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtCond\",\n",
    "    \"BsmtFinType2\",\n",
    "]\n",
    "for col in categorical_fillna:\n",
    "    train_df[col].fillna(\"No\", inplace=True)\n",
    "    test_df[col].fillna(\"No\", inplace=True)\n",
    "\n",
    "train_df[\"BsmtFinType1\"].fillna(\"Unf\", inplace=True)\n",
    "test_df[\"BsmtFinType1\"].fillna(\"Unf\", inplace=True)\n",
    "train_df[\"Electrical\"].fillna(\"SBrkr\", inplace=True)\n",
    "test_df[\"Electrical\"].fillna(\"SBrkr\", inplace=True)\n",
    "train_df[\"LotFrontage\"].fillna(0, inplace=True)\n",
    "test_df[\"LotFrontage\"].fillna(0, inplace=True)\n",
    "train_df[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "test_df[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "\n",
    "print(f\"Missing values handled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features engineered\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    \"PoolQC\",\n",
    "    \"MiscFeature\",\n",
    "    \"Alley\",\n",
    "    \"Fence\",\n",
    "    \"GarageYrBlt\",\n",
    "    \"GarageCond\",\n",
    "    \"BsmtFinType2\",\n",
    "]\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "test_df = test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "train_df[\"houseage\"] = train_df[\"YrSold\"] - train_df[\"YearBuilt\"]\n",
    "test_df[\"houseage\"] = test_df[\"YrSold\"] - test_df[\"YearBuilt\"]\n",
    "train_df[\"houseremodelage\"] = train_df[\"YrSold\"] - train_df[\"YearRemodAdd\"]\n",
    "test_df[\"houseremodelage\"] = test_df[\"YrSold\"] - test_df[\"YearRemodAdd\"]\n",
    "train_df[\"totalsf\"] = (\n",
    "    train_df[\"1stFlrSF\"] + train_df[\"2ndFlrSF\"] + train_df[\"BsmtFinSF1\"] + train_df[\"BsmtFinSF2\"]\n",
    ")\n",
    "test_df[\"totalsf\"] = (\n",
    "    test_df[\"1stFlrSF\"] + test_df[\"2ndFlrSF\"] + test_df[\"BsmtFinSF1\"] + test_df[\"BsmtFinSF2\"]\n",
    ")\n",
    "train_df[\"totalbaths\"] = (\n",
    "    train_df[\"BsmtFullBath\"]\n",
    "    + train_df[\"FullBath\"]\n",
    "    + 0.5 * (train_df[\"BsmtHalfBath\"] + train_df[\"HalfBath\"])\n",
    ")\n",
    "test_df[\"totalbaths\"] = (\n",
    "    test_df[\"BsmtFullBath\"]\n",
    "    + test_df[\"FullBath\"]\n",
    "    + 0.5 * (test_df[\"BsmtHalfBath\"] + test_df[\"HalfBath\"])\n",
    ")\n",
    "train_df[\"totalporchsf\"] = (\n",
    "    train_df[\"OpenPorchSF\"]\n",
    "    + train_df[\"3SsnPorch\"]\n",
    "    + train_df[\"EnclosedPorch\"]\n",
    "    + train_df[\"ScreenPorch\"]\n",
    "    + train_df[\"WoodDeckSF\"]\n",
    ")\n",
    "test_df[\"totalporchsf\"] = (\n",
    "    test_df[\"OpenPorchSF\"]\n",
    "    + test_df[\"3SsnPorch\"]\n",
    "    + test_df[\"EnclosedPorch\"]\n",
    "    + test_df[\"ScreenPorch\"]\n",
    "    + test_df[\"WoodDeckSF\"]\n",
    ")\n",
    "\n",
    "columns_to_drop_fe = [\n",
    "    \"Id\",\n",
    "    \"YrSold\",\n",
    "    \"YearBuilt\",\n",
    "    \"YearRemodAdd\",\n",
    "    \"1stFlrSF\",\n",
    "    \"2ndFlrSF\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"BsmtFinSF2\",\n",
    "    \"GrLivArea\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"FullBath\",\n",
    "    \"BsmtHalfBath\",\n",
    "    \"HalfBath\",\n",
    "    \"OpenPorchSF\",\n",
    "    \"3SsnPorch\",\n",
    "    \"EnclosedPorch\",\n",
    "    \"ScreenPorch\",\n",
    "    \"WoodDeckSF\",\n",
    "]\n",
    "train_df = train_df.drop(columns=columns_to_drop_fe)\n",
    "test_id = test_df[\"Id\"].copy()\n",
    "test_df = test_df.drop(columns=[col for col in columns_to_drop_fe if col in test_df.columns])\n",
    "\n",
    "if \"GarageArea\" in train_df.columns:\n",
    "    train_df = train_df.drop(columns=[\"GarageArea\"])\n",
    "if \"GarageArea\" in test_df.columns:\n",
    "    test_df = test_df.drop(columns=[\"GarageArea\"])\n",
    "\n",
    "print(\"Features engineered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features saved to 03-features folder\n"
     ]
    }
   ],
   "source": [
    "train_df.to_csv(\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/HOUSE PRICES - ADVANCED REGRESSION TECHNIQUES/data/03-features/train_features.csv\",\n",
    "    index=False,\n",
    ")\n",
    "test_df.to_csv(\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/HOUSE PRICES - ADVANCED REGRESSION TECHNIQUES/data/03-features/test_features.csv\",\n",
    "    index=False,\n",
    ")\n",
    "print(\"Engineered features saved to 03-features folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Target Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice log-transformed\n"
     ]
    }
   ],
   "source": [
    "train_df[\"SalePrice\"] = np.log1p(train_df[\"SalePrice\"])\n",
    "print(\"SalePrice log-transformed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: 21, Ordinal: 18, OneHot: 19\n"
     ]
    }
   ],
   "source": [
    "ordinal_encoder_cols = [\n",
    "    \"LotShape\",\n",
    "    \"LandContour\",\n",
    "    \"Utilities\",\n",
    "    \"LandSlope\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtFinType1\",\n",
    "    \"CentralAir\",\n",
    "    \"Functional\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageFinish\",\n",
    "    \"GarageQual\",\n",
    "    \"PavedDrive\",\n",
    "    \"ExterCond\",\n",
    "    \"KitchenQual\",\n",
    "    \"BsmtExposure\",\n",
    "    \"HeatingQC\",\n",
    "    \"ExterQual\",\n",
    "    \"BsmtCond\",\n",
    "]\n",
    "one_hot_encoder_cols = [\n",
    "    \"Street\",\n",
    "    \"LotConfig\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"RoofStyle\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"Foundation\",\n",
    "    \"Electrical\",\n",
    "    \"SaleType\",\n",
    "    \"MSZoning\",\n",
    "    \"SaleCondition\",\n",
    "    \"Heating\",\n",
    "    \"GarageType\",\n",
    "    \"RoofMatl\",\n",
    "]\n",
    "numeric_cols = train_df.select_dtypes(include=[\"int64\", \"float64\"]).columns.drop(\"SalePrice\")\n",
    "print(\n",
    "    f\"Numeric: {len(numeric_cols)}, Ordinal: {len(ordinal_encoder_cols)}, OneHot: {len(one_hot_encoder_cols)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipelines created\n"
     ]
    }
   ],
   "source": [
    "numeric_pipeline = Pipeline(\n",
    "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "ordinal_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ]\n",
    ")\n",
    "onehot_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, numeric_cols),\n",
    "        (\"ordinal\", ordinal_pipeline, ordinal_encoder_cols),\n",
    "        (\"onehot\", onehot_pipeline, one_hot_encoder_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "print(\"Pipelines created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1151, 193), X_test: (288, 193)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop(\"SalePrice\", axis=1)\n",
    "y = train_df[\"SalePrice\"]\n",
    "X_preprocessed = col_transformer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, y, test_size=0.2, random_state=25\n",
    ")\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.133129\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "print(f\"Linear Regression RMSE: {rmse_lr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF RMSE: 0.136380\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(random_state=13)\n",
    "param_grid_rfr = {\n",
    "    \"max_depth\": [5, 10, 15],\n",
    "    \"n_estimators\": [100, 250, 500],\n",
    "    \"min_samples_split\": [3, 5, 10],\n",
    "}\n",
    "rfr_cv = GridSearchCV(rfr, param_grid_rfr, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "rfr_cv.fit(X_train, y_train)\n",
    "rmse_rfr = np.sqrt(-1 * rfr_cv.best_score_)\n",
    "print(f\"RF RMSE: {rmse_rfr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR RMSE: 0.118121\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=13)\n",
    "param_grid_gbr = {\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"min_samples_leaf\": [5, 10, 20],\n",
    "}\n",
    "gbr_cv = GridSearchCV(gbr, param_grid_gbr, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "gbr_cv.fit(X_train, y_train)\n",
    "rmse_gbr = np.sqrt(-1 * gbr_cv.best_score_)\n",
    "print(f\"GBR RMSE: {rmse_gbr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. XGBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE: 0.119380\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(random_state=13)\n",
    "param_grid_xgb = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "}\n",
    "xgb_cv = GridSearchCV(xgb, param_grid_xgb, cv=3, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "rmse_xgb = np.sqrt(-1 * xgb_cv.best_score_)\n",
    "print(f\"XGB RMSE: {rmse_xgb:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting RMSE: 0.121672\n"
     ]
    }
   ],
   "source": [
    "vr = VotingRegressor(\n",
    "    [(\"gbr\", gbr_cv.best_estimator_), (\"xgb\", xgb_cv.best_estimator_)], weights=[1, 1]\n",
    ")\n",
    "vr.fit(X_train, y_train)\n",
    "y_pred_vr = vr.predict(X_test)\n",
    "rmse_vr = np.sqrt(mean_squared_error(y_test, y_pred_vr))\n",
    "print(f\"Voting RMSE: {rmse_vr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Stacking Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking RMSE: 0.121442\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    (\"gbr\", gbr_cv.best_estimator_),\n",
    "    (\"xgb\", xgb_cv.best_estimator_),\n",
    "    (\"rfr\", rfr_cv.best_estimator_),\n",
    "]\n",
    "stackreg = StackingRegressor(estimators=estimators, final_estimator=Ridge(alpha=1.0), cv=5)\n",
    "stackreg.fit(X_train, y_train)\n",
    "y_pred_stack = stackreg.predict(X_test)\n",
    "rmse_stack = np.sqrt(mean_squared_error(y_test, y_pred_stack))\n",
    "print(f\"Stacking RMSE: {rmse_stack:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nModel Comparison:\n",
      "               Model      RMSE\n",
      "0  Gradient Boosting  0.118121\n",
      "1            XGBoost  0.119380\n",
      "2           Stacking  0.121442\n",
      "3             Voting  0.121672\n",
      "4  Linear Regression  0.133129\n",
      "5      Random Forest  0.136380\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"Linear Regression\",\n",
    "            \"Random Forest\",\n",
    "            \"Gradient Boosting\",\n",
    "            \"XGBoost\",\n",
    "            \"Voting\",\n",
    "            \"Stacking\",\n",
    "        ],\n",
    "        \"RMSE\": [rmse_lr, rmse_rfr, rmse_gbr, rmse_xgb, rmse_vr, rmse_stack],\n",
    "    }\n",
    ")\n",
    "results = results.sort_values(\"RMSE\").reset_index(drop=True)\n",
    "print(\"\\\\nModel Comparison:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (1459,)\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = col_transformer.transform(test_df)\n",
    "y_pred_test = stackreg.predict(X_test_preprocessed)\n",
    "y_pred_test = np.exp(y_pred_test) - 1\n",
    "print(f\"Predictions shape: {y_pred_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n",
      "     Id      SalePrice\n",
      "0  1461  128310.204680\n",
      "1  1462  168082.754369\n",
      "2  1463  175835.094094\n",
      "3  1464  196900.160106\n",
      "4  1465  189916.623593\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"Id\": test_id, \"SalePrice\": y_pred_test})\n",
    "submission.to_csv(\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/HOUSE PRICES - ADVANCED REGRESSION TECHNIQUES/data/04-predictions/submission.csv\",\n",
    "    index=False,\n",
    ")\n",
    "print(\"Submission saved\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "califonia_housing_prices",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
